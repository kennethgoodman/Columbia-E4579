{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NC29c_YJNFJ"
   },
   "source": [
    "# **Guidelines**\n",
    "\n",
    "## Process Overview\n",
    "The ranking step includes 2 sub-processes:\n",
    "1. Scoring: In this step, you will train a scoring model to predict 3 types of score; probability of like, probability of dislike, and engagement time.\n",
    "2. Ranking: In this step, you will create a ranking policy to rank the items based on the output from previous step.\n",
    "\n",
    "\n",
    "## Your Task\n",
    "\n",
    "### 1. Modify `DataCollectorExample()`\n",
    "also rename it to `DataCollector{Team}()` juts like previous assignment. All of the functions in `DataCollectorExample()` need to be modified (They're the ones with `raise NotImplementedError(\"you need to implement this\")` in `DataCollector()`). The explaination of each function includes in their own docstring with example code.\n",
    "\n",
    "Some important points worth noting are:\n",
    "1. for `.feature_generation_user()` and `.feature_generation_content()`, you DO NOT need to apply one-hot encoding or scaler since this process will be done by our pipeline using via `.postprocess_feature()`, which will also save the `Postprocessor()` class as a pickle file to be used for testing and inference step. You will need to output nsames of numberical features and categorical features along with the feature dataframe.\n",
    "2. When engineering target variables with `.get_Ys()`, you'll need to output 3 columns of target variables (`'like'`, `'dislike'`, `'engage_time'`). Be careful of how you create each target variable. What happen if a user like an item then change their mind and dislike it? What if a user see the same content twice, what would be the engagement time?\n",
    "3. Be creative of how you would create your ranking policy in `.rank()`. You have 3 scores that your ranking can be based on. Which score(s) would you optimise your ranking for? How would you trade-off one with others? Can you rank base on all 3 of them, if so, how would you combine them? You can also join the score dataframe with `self.generated_content_metadata` to use the original content features as part of ranking.\n",
    "\n",
    "### 2. Train Model\n",
    "Use the cell `Training: Create your own training` to train your model. Feel free to select any model you like. In the example, I use train 1 model for each target variable, resulting in 3 models. If you can find a model that can produce 3 output values (e.g. Neural Network), feel free to do so.\n",
    "\n",
    "Some important points worth noting are:\n",
    "1. Make sure you save the model to **ONLY 1 file**. Even if you make 3 models, put them into a list or dictionary and save the whole object to 1 file.\n",
    "2. Depending on your modelling approach, you'll need your own way to load the model to make predictions. Thus, modify the `.load_model()` in `DataCollectorExample()` reflect this.\n",
    "3. Once you train your model, you can use the example evaluation cells to evaluate your model. There's no need to change anything about the evaluation except the thresholds variable. These thresholds decide at what probability we'll consider the prediction as like and dislike. **NOTE** that this only test your scoring model, not your ranking policy. Testing for ranking policy is much more complicated since we're not only optimizing the number of likes and thus cannot be done offline.\n",
    "\n",
    "\n",
    "# Test Your Model\n",
    "Once you have the scoring model and ranking policy, you can use the `Inference Example` cell to run your pipeline and see the output of recommended items from your model.\n",
    "\n",
    "# Submit your work\n",
    "\n",
    "1. Put `postprocessor.pkl` and your model file into `Columbia-E4579/services/backend/src/recommendation_system/recommendation_flow/model_prediction` folder on your branch. Make sure to rename them as `{team}_postprocessor.pkl` and `{team}_model.pkl` (E.g. `alpha_postprocessor.pkl` and `alpha_model.pkl`). Both `postprocessor.pkl` and your model file will be saved in `sampled_data` in your COlab work space. Since this workspace is cleared everytime you restart the Colab, please also save the postprocessor and model files on your local machine if you want to keep them.\n",
    "\n",
    "2. Download your Colab as `.ipynb` file, rename it as `{team}_ranking.ipynb` (e.g. `alpha_ranking.ipynb`), and also place it in `Columbia-E4579/services/backend/src/recommendation_system/recommendation_flow/model_prediction` folder on your branch.\n",
    "\n",
    "You'll then merge your branch with these files into Professor's branch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBiX1FEG1nXj"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkuqgSAjwlnY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from google.colab import drive\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSXqZ70o1omv"
   },
   "source": [
    "# DataCollector - Do Not Modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CMmBKnre2Hv"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy.sql.schema import ScalarElementColumnDefault\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Optional\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Postprocessor:\n",
    "    def __init__(self,\n",
    "                 numberical_features: List[str],\n",
    "                 categorical_features: List[str]):\n",
    "\n",
    "        self.numberical_features = numberical_features\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self.encode_cols = []\n",
    "\n",
    "    def fit(self, features_df: pd.DataFrame):\n",
    "\n",
    "        self.scaler.fit(features_df[self.numberical_features])\n",
    "\n",
    "        if len(self.categorical_features) > 0:\n",
    "            self.encoder.fit(features_df[self.categorical_features])\n",
    "            self.encode_cols = list(self.encoder.get_feature_names_out())\n",
    "\n",
    "    def transform(self, features_df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        features_df[self.numberical_features] = self.scaler.transform(features_df[self.numberical_features])\n",
    "\n",
    "        if len(self.categorical_features) > 0:\n",
    "            features_df[self.encode_cols] = self.encoder.transform(features_df[self.categorical_features])\n",
    "\n",
    "        return features_df\n",
    "\n",
    "    def fit_transform(self, features_df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        self.fit(features_df)\n",
    "        features_df = self.transform(features_df)\n",
    "\n",
    "        return features_df\n",
    "\n",
    "\n",
    "class DataCollector:\n",
    "    def __init__(self,\n",
    "                 engagement_path=None,\n",
    "                 content_meta_path=None):\n",
    "\n",
    "\n",
    "        self.engagement_path = engagement_path\n",
    "        self.content_meta_path = content_meta_path\n",
    "\n",
    "        self.objects_dir = 'sample_data'  #TODO change this\n",
    "        self.numerical_features = []\n",
    "        self.categorical_features = []\n",
    "\n",
    "        self.postprocessor = None\n",
    "        self.model = None\n",
    "\n",
    "    def feature_generation_user(self) -> Tuple[pd.DataFrame, List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Returns\n",
    "          pd.DataFrame: User feature dataframe\n",
    "          List[str]: List of numerical features. E.g. ['feat_1', 'feat_3, ...]\n",
    "          List[str]: List of categorical features. E.g. ['feat_2', 'feat_4, ...]\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"you need to implement this\")\n",
    "\n",
    "    def feature_generation_content(self) -> Tuple[pd.DataFrame, List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Returns\n",
    "          pd.DataFrame: Content feature dataframe\n",
    "          List[str]: List of numerical features. E.g. ['feat_1', 'feat_3, ...]\n",
    "          List[str]: List of categorical features. E.g. ['feat_2', 'feat_4, ...]\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"you need to implement this\")\n",
    "\n",
    "    def get_Ys(self) -> pd.DataFrame:\n",
    "        \"\"\"Engineers taget variable.\n",
    "        Args\n",
    "            data (pd.DataFrame): Engagement data.\n",
    "        Returns\n",
    "            pd.DataFrame: Dataframe of 5 columns;\n",
    "                'user_id', 'content_id', 'like', 'dislike', 'engage_time'\n",
    "        \"\"\"\n",
    "\n",
    "        raise NotImplementedError(\"you need to implement this\")\n",
    "\n",
    "    def feature_generation(self, is_train=False) -> pd.DataFrame:\n",
    "        \"\"\"Generate features. If is_train, will generate features for user-content pairs\n",
    "        exist in self.engagement_data. Else, will generate features for\n",
    "        all possible user-content pairs.\n",
    "\n",
    "        Args:\n",
    "            is_train (bool): Whether in training mode.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Feature dataframe.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        user_feature_df, user_num_feats, user_cat_feats = self.feature_generation_user()\n",
    "        content_feature_df, content_num_feats, content_cat_feats = self.feature_generation_content()\n",
    "        self.user_feature_df = user_feature_df\n",
    "        self.content_feature_df = content_feature_df\n",
    "\n",
    "        self.numerical_features = user_num_feats + content_num_feats\n",
    "        self.categorical_features = user_cat_feats + content_cat_feats\n",
    "\n",
    "        if is_train:\n",
    "            interaction_pairs = self.engagement_data[\n",
    "                ['user_id', 'content_id']].drop_duplicates()\n",
    "\n",
    "        else:\n",
    "            all_users = self.engagement_data['user_id'].drop_duplicates().tolist()\n",
    "            all_contents = self.generated_content_metadata['content_id'].drop_duplicates().tolist()\n",
    "\n",
    "            interaction_pairs = [(u, c) for u in all_users for c in all_contents]\n",
    "            interaction_pairs = pd.DataFrame(interaction_pairs, columns=['user_id', 'content_id'])\n",
    "\n",
    "        features_df = pd.merge(interaction_pairs,\n",
    "                               user_feature_df, on='user_id', how='left')\n",
    "\n",
    "        features_df = pd.merge(features_df,\n",
    "                               content_feature_df, on='content_id', how='left')\n",
    "\n",
    "        return features_df\n",
    "\n",
    "\n",
    "    def get_engagement_data(self, user_id=None, content_ids=None):\n",
    "\n",
    "        if self.engagement_path is None:\n",
    "            #TODO: read from database\n",
    "            pass\n",
    "        else:\n",
    "            df = pd.read_csv(self.engagement_path, sep=\"\\t\")\n",
    "\n",
    "        if content_ids is not None:\n",
    "            df = df[df['content_id'].isin(content_ids)]\n",
    "\n",
    "        if user_id is not None:\n",
    "            df = df[df['user_id'] == user_id]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_generated_content_metadata(self, content_ids=None):\n",
    "\n",
    "        if self.content_meta_path is None:\n",
    "            #TODO: read from database\n",
    "            pass\n",
    "        else:\n",
    "            df = pd.read_csv(self.content_meta_path, sep=\"\\t\")\n",
    "\n",
    "        if content_ids is not None:\n",
    "            df = df[df['content_id'].isin(content_ids)]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_user_data(self, user_id=None):\n",
    "\n",
    "        if self.engagement_path is None:\n",
    "            #TODO: read from database\n",
    "            pass\n",
    "        else:\n",
    "            df = pd.read_csv(self.engagement_path, sep=\"\\t\")\n",
    "\n",
    "        if user_id is not None:\n",
    "            df = df[df['user_id'] == user_id]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def gather_data(self, user_id, content_ids):\n",
    "        self.engagement_data = self.get_engagement_data(user_id, content_ids)\n",
    "        self.generated_content_metadata = self.get_generated_content_metadata(content_ids)\n",
    "        self.user_data = self.get_user_data(user_id)\n",
    "\n",
    "        if len(self.engagement_data) == 0:\n",
    "            raise Exception(\"either user_id or content_ids leads to empty engagement_data\")\n",
    "\n",
    "        if len(self.generated_content_metadata) == 0:\n",
    "            raise Exception(\"content_ids leads to empty generated_content_metadata\")\n",
    "\n",
    "        if len(self.user_data) == 0:\n",
    "            raise Exception(\"user_id leads to empty user_data\")\n",
    "\n",
    "    def postprocess_feature(self, features_df: pd.DataFrame, is_train=False) -> pd.DataFrame:\n",
    "        \"\"\"Applied postprocessings (one-hot encoding & scaler) to the feature dataframe.\n",
    "\n",
    "        Args:\n",
    "            features_df (pd.DataFrame): Input feature dataframe.\n",
    "            is_train (bool): Whether in training mode. If True, will fit the\n",
    "                Postprocessor() and save to a pickle file. Else, will load the\n",
    "                saved Postprocessor() and use it.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Output feature dataframe.\n",
    "        \"\"\"\n",
    "\n",
    "        if is_train:\n",
    "            self.postprocessor = Postprocessor(self.numerical_features, self.categorical_features)\n",
    "            features_df = self.postprocessor.fit_transform(features_df)\n",
    "            self.save_postprocessor()\n",
    "\n",
    "        else:\n",
    "            self.postprocessor = self.load_postprocessor()\n",
    "            features_df = self.postprocessor.transform(features_df)\n",
    "\n",
    "        self.all_numeric_features = self.numerical_features + self.postprocessor.encode_cols\n",
    "\n",
    "\n",
    "        return features_df\n",
    "\n",
    "\n",
    "    def gen_model_input(self,\n",
    "                        user_id: Optional[int] = None,\n",
    "                        content_ids: Optional[list] = None,\n",
    "                        is_train: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"Generates input data (X) for model.\n",
    "\n",
    "        Args:\n",
    "            user_id (Optional[int]): User ID to generate features for.\n",
    "                If None, will generate features for all available users in self.engagement_data.\n",
    "            content_ids (Optional[list]): List of content ID to generate features for.\n",
    "                If None, will generate features for all available contents in self.engagement_data.\n",
    "            is_train (bool): Whether in training mode. If True, will generate\n",
    "                features for user-content pairs exist in self.engagement_data.\n",
    "                Else, will generate features for all possible user-content pairs.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Dataframe of features with 2-level index of ('user_id', 'content_id').\n",
    "        \"\"\"\n",
    "\n",
    "        self.gather_data(user_id, content_ids)\n",
    "        features_df = self.feature_generation(is_train)\n",
    "        features_df = self.postprocess_feature(features_df, is_train)\n",
    "\n",
    "        X = features_df.set_index(['user_id', 'content_id'])\n",
    "        X = X[self.all_numeric_features]\n",
    "        X = X.fillna(0)\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "    def gen_target_vars(self,\n",
    "                        engagement_data: Optional[pd.DataFrame] = None\n",
    "                        ) -> pd.DataFrame:\n",
    "        \"\"\"Wrapper to generate target variables.\n",
    "\n",
    "        Args:\n",
    "            engagement_data (Optional[pd.DataFrame]): Engagement data. If None,\n",
    "                will use self.engagement_data which is loaded for training.\n",
    "                For testing, parse in the engagement_data for testing.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Dataframe of 3 columns; 'like', 'dislike', 'engage_time'\n",
    "                and 2-level index of ('user_id', 'content_id').\n",
    "        \"\"\"\n",
    "\n",
    "        if engagement_data is None:\n",
    "            engagement_data = self.engagement_data\n",
    "\n",
    "        target_df = self.get_Ys(engagement_data)\n",
    "\n",
    "        return target_df.set_index(['user_id', 'content_id'])\n",
    "\n",
    "\n",
    "    def save_postprocessor(self):\n",
    "        with open(f'{self.objects_dir}/postprocessor.pkl', 'wb') as f:\n",
    "            pickle.dump(self.postprocessor, f)\n",
    "\n",
    "    def load_postprocessor(self):\n",
    "        with open(f'{self.objects_dir}/postprocessor.pkl', 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def load_model(self):\n",
    "        raise NotImplementedError(\"you need to implement this\")\n",
    "\n",
    "    def predict(self, X) -> Tuple[list, list, list]:\n",
    "        raise NotImplementedError(\"you need to implement this\")\n",
    "\n",
    "    def rank(self, pred_score):\n",
    "        raise NotImplementedError(\"you need to implement this\")\n",
    "\n",
    "    def score(self,\n",
    "              user_id: Optional[int] = None,\n",
    "              content_ids: Optional[list] = None) -> pd.DataFrame:\n",
    "        \"\"\"Predict the scores.\n",
    "\n",
    "        Args:\n",
    "            user_id (Optional[int]): User ID to generate features for.\n",
    "                If None, will generate features for all available users in self.engagement_data.\n",
    "            content_ids (Optional[list]): List of content ID to generate features for.\n",
    "                If None, will generate features for all available contents in self.engagement_data.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Predicted score dataframe with 2-level index of (user_id, content_id).\n",
    "                The dataframe also comes with the original content metadata which also\n",
    "                can be used for ranking.\n",
    "        \"\"\"\n",
    "\n",
    "        X = self.gen_model_input(user_id, content_ids, is_train=False)\n",
    "\n",
    "        pred_like, pred_dislike, pred_engtime = self.predict(X)\n",
    "\n",
    "        pred_df = pd.DataFrame(np.array([pred_like, pred_dislike, pred_engtime]).T,\n",
    "                               index=X.index,\n",
    "                               columns=['like', 'dislike', 'engage_time']).reset_index()\n",
    "\n",
    "        pred_df = pd.merge(self.generated_content_metadata,\n",
    "                           pred_df,\n",
    "                           how='right',\n",
    "                           on='content_id')\n",
    "\n",
    "        return pred_df.set_index(['user_id', 'content_id'])\n",
    "\n",
    "    def recommend(self, user_id, content_ids=None, top_k=20):\n",
    "\n",
    "        score_df = self.score(user_id, content_ids).reset_index()\n",
    "\n",
    "        rank = self.rank(score_df, user_id, content_ids)\n",
    "\n",
    "        return rank[:top_k]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLGG-J71qkzp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def evaluate(true_df: pd.DataFrame,\n",
    "             pred_df: pd.DataFrame,\n",
    "             thres_like: float = 0.5,\n",
    "             thres_dislike: float = 0.5\n",
    "             ) -> dict:\n",
    "\n",
    "    \"\"\"Compute evaluation metrics.\n",
    "\n",
    "    Args:\n",
    "        true_df (pd.DataFrame): Dataframe of true target variables.\n",
    "        pred_df (pd.DataFrame): Dataframe of predicted target variables.\n",
    "        thres_like (float): Probability threshold to consider a prediction as like.\n",
    "        thres_dislike (float): Probability threshold to consider as a prediction dislike.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    true_df = true_df.reset_index()\n",
    "    pred_df = pred_df[['like', 'dislike', 'engage_time']].reset_index()\n",
    "\n",
    "    pred_df['like'] = (pred_df['like'] > thres_like).astype(int)\n",
    "    pred_df['dislike'] = (pred_df['dislike'] > thres_dislike).astype(int)\n",
    "\n",
    "    actual_user_content = true_df[['user_id', 'content_id']]\n",
    "    pred_user_content = pred_df[['user_id', 'content_id']]\n",
    "\n",
    "    common_user_content = pd.merge(actual_user_content,\n",
    "                                   pred_user_content,\n",
    "                                   how='inner',\n",
    "                                   on=['user_id', 'content_id'])\n",
    "\n",
    "    true_df = pd.merge(common_user_content,\n",
    "                         true_df,\n",
    "                         how='left',\n",
    "                         on=['user_id', 'content_id'])\n",
    "\n",
    "\n",
    "    pred_df = pd.merge(common_user_content,\n",
    "                       pred_df,\n",
    "                       how='left',\n",
    "                       on=['user_id', 'content_id'])\n",
    "\n",
    "\n",
    "    metrics = {}\n",
    "    for col in ['like', 'dislike', 'engage_time']:\n",
    "        metrics[col] = {}\n",
    "\n",
    "        if col == 'engage_time':\n",
    "            metrics[col]['rmse'] = np.sqrt(mean_squared_error(true_df[col], pred_df[col]))\n",
    "        else:\n",
    "            metrics[col]['precision'] = precision_score(true_df[col], pred_df[col])\n",
    "            metrics[col]['recall'] = recall_score(true_df[col], pred_df[col])\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA9SBLao1s4f"
   },
   "source": [
    "# Your Implementation - Example Here, Must Modify\n",
    "# Archit plz edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gD1H4oVokqqR"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "class DataCollectorGolf(DataCollector):\n",
    "    def feature_generation_user(self) -> Tuple[pd.DataFrame, List[str], List[str]]:\n",
    "        # Assuming self.engagement_data contains the engagement data\n",
    "        user_data = self.get_user_data()\n",
    "\n",
    "        # Group by user_id and aggregate features\n",
    "        user_features = user_data.groupby('user_id').agg(\n",
    "            categorical_feature=('engagement_type', lambda x: x.mode()[0]),\n",
    "            numerical_feature=('engagement_value', 'mean'),\n",
    "            latest_created_date=('created_date', 'max')\n",
    "        ).reset_index()\n",
    "\n",
    "        # Convert created_date to a numerical feature representing the time elapsed since the latest engagement\n",
    "        user_features['latest_created_date'] = (datetime.now() - pd.to_datetime(user_features['latest_created_date'])).dt.total_seconds()\n",
    "\n",
    "        # Rename columns for clarity\n",
    "        user_features.rename(columns={\n",
    "            'categorical_feature': 'user_categorical_feature',\n",
    "            'numerical_feature': 'user_numerical_feature',\n",
    "            'latest_created_date': 'user_time_elapsed'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Define lists of numerical and categorical features\n",
    "        numerical_features = ['user_numerical_feature', 'user_time_elapsed']\n",
    "        categorical_features = ['user_categorical_feature']\n",
    "\n",
    "        return user_features, numerical_features, categorical_features\n",
    "\n",
    "\n",
    "    def feature_generation_content(self) -> Tuple[pd.DataFrame, List[str], List[str]]:\n",
    "\n",
    "\n",
    "        # Assuming self.generated_content_metadata contains the content metadata\n",
    "        content_features = self.generated_content_metadata[['content_id', 'guidance_scale', 'num_inference_steps', 'source']].copy()\n",
    "\n",
    "        # One-hot encode the 'source' column\n",
    "        content_features = pd.get_dummies(content_features, columns=['source'], prefix='content_source')\n",
    "\n",
    "        # Rename columns for clarity\n",
    "        content_features.rename(columns={\n",
    "            'guidance_scale': 'content_numerical_feature_guidance_scale',\n",
    "            'num_inference_steps': 'content_numerical_feature_num_inference_steps',\n",
    "            'content_source_human_prompts': 'content_source_human_prompts',\n",
    "            'content_source_r/pics': 'content_source_r/pics',\n",
    "            'content_source_r/scifi': 'content_source_r/scifi'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Define lists of numerical and categorical features\n",
    "        numerical_features = ['content_numerical_feature_guidance_scale', 'content_numerical_feature_num_inference_steps']\n",
    "        categorical_features = ['content_source_human_prompts', 'content_source_r/pics', 'content_source_r/scifi']\n",
    "\n",
    "        return content_features, numerical_features, categorical_features\n",
    "\n",
    "    def get_Ys(self, engagement_data) -> pd.DataFrame:\n",
    "        # Initialize target_df with user_id and content_id\n",
    "        target_df = engagement_data[['user_id', 'content_id']].drop_duplicates().copy()\n",
    "\n",
    "        # Initialize columns for like, dislike, and engage_time\n",
    "        target_df['like'] = 0\n",
    "        target_df['dislike'] = 0\n",
    "        target_df['engage_time'] = 0.0\n",
    "\n",
    "        # Set like and dislike based on engagement_type and engagement_value\n",
    "        like_mask = (engagement_data['engagement_type'] == 'Like') & (engagement_data['engagement_value'] == 1)\n",
    "        dislike_mask = (engagement_data['engagement_type'] == 'Like') & (engagement_data['engagement_value'] == -1)\n",
    "\n",
    "        target_df.loc[like_mask, 'like'] = 1\n",
    "        target_df.loc[dislike_mask, 'dislike'] = 1\n",
    "\n",
    "        # Set engage_time based on engagement_type and engagement_value\n",
    "        time_mask = (engagement_data['engagement_type'] == 'MillisecondsEngagedWith')\n",
    "        target_df.loc[time_mask, 'engage_time'] = engagement_data.loc[time_mask, 'engagement_value']\n",
    "\n",
    "        # Reset the index to include user_id and content_id as columns\n",
    "        target_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return target_df\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> Tuple[list, list, list]:\n",
    "        \"\"\"Predicts the 3 target variables by using the model that you trained.\n",
    "        Make sure you load the model properly.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Feature dataframe with 2-level index of (user_id, content_id)\n",
    "\n",
    "        Returns:\n",
    "            (list, list, list): (predicted prbability of like,\n",
    "                                 predicted probability of dislike,\n",
    "                                 predicted engagement time)\n",
    "        \"\"\"\n",
    "\n",
    "        model = self.load_model()\n",
    "\n",
    "        pred_like = model['like'].predict(X)\n",
    "        pred_dislike = model['dislike'].predict(X)\n",
    "        pred_engtime = model['engage_time'].predict(X)\n",
    "\n",
    "        lenx =len(X)\n",
    "        frac = int(lenx/7)\n",
    "        pred_like[-frac:] = np.random.uniform(0, 1, frac)\n",
    "        pred_dislike[-frac:] = np.random.uniform(0, 1, frac)\n",
    "        pred_engtime[-frac:] = np.random.uniform(0, 1, frac)\n",
    "\n",
    "        return pred_like, pred_dislike, pred_engtime\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    def rank(self,\n",
    "                    score_df: pd.DataFrame,\n",
    "                    user_id: int,\n",
    "                    content_ids: Optional[list] = None) -> list:\n",
    "\n",
    "          # Filter user\n",
    "          user_df = score_df[score_df['user_id'] == user_id]\n",
    "\n",
    "          if content_ids is not None:\n",
    "              user_df = user_df[user_df['content_id'].isin(content_ids)]\n",
    "\n",
    "          # Add random columns if missing\n",
    "          if 'user_numerical_feature' not in user_df.columns:\n",
    "              user_df['user_numerical_feature'] = np.random.rand(len(user_df))\n",
    "\n",
    "          if 'user_time_elapsed' not in user_df.columns:\n",
    "              user_df['user_time_elapsed'] = np.random.rand(len(user_df))\n",
    "\n",
    "          # Calculate score\n",
    "          weights = {}\n",
    "          weights['like'] = user_df['user_numerical_feature'].mean()/100\n",
    "          weights['dislike'] = -weights['like']/2\n",
    "          weights['engage_time'] = user_df['user_time_elapsed'].mean()/100\n",
    "\n",
    "          user_df['score'] = user_df['like']*weights['like'] + user_df['dislike']*weights['dislike'] + user_df['engage_time']*weights['engage_time']\n",
    "\n",
    "\n",
    "          # Rank\n",
    "          ranked_df = user_df.sort_values('score', ascending=False)\n",
    "\n",
    "          return ranked_df['content_id'][:20].tolist()\n",
    "\n",
    "    def load_model(self) -> object:\n",
    "        \"\"\"Loads your model. Since different ML frameworks requires different\n",
    "        ways to load the model. Change this to reflect your choice of framework.\n",
    "\n",
    "        Returns:\n",
    "            object: Model object\n",
    "        \"\"\"\n",
    "\n",
    "        with open(f'{self.objects_dir}/model.pkl', 'rb') as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4-hYYzK8vuA",
    "outputId": "6763d1f5-c9aa-4b11-b014-6588a9737ec5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPKXbKCze2mF"
   },
   "outputs": [],
   "source": [
    "# class DataCollectorExample(DataCollector):\n",
    "\n",
    "#     def feature_generation_user(self) -> Tuple[pd.DataFrame, List[str], List[str]]:\n",
    "#         \"\"\"Generates user features. Keep all the categorical variables as is,\n",
    "#         since the one-hot encoding will be done by our own pipeline. Along with\n",
    "#         the feature dataframe, you'll need to output lists of numberical features\n",
    "#         and categorical features as well.\n",
    "\n",
    "#         Returns\n",
    "#           pd.DataFrame: User feature dataframe\n",
    "#           List[str]: List of numerical features. E.g. ['feat_1', 'feat_3, ...]\n",
    "#           List[str]: List of categorical features. E.g. ['feat_2', 'feat_4, ...]\n",
    "#         \"\"\"\n",
    "\n",
    "#         feature_df = self.user_data[['user_id']].drop_duplicates().copy()\n",
    "\n",
    "#         np.random.seed(42)\n",
    "#         feature_df[['user_feat_0', 'user_feat_1']] = np.random.rand(len(feature_df), 2)\n",
    "\n",
    "#         return feature_df, ['user_feat_0', 'user_feat_1'], []\n",
    "\n",
    "#     def feature_generation_content(self) -> Tuple[pd.DataFrame, List[str], List[str]]:\n",
    "#         \"\"\"Generates content features. Keep all the categorical variables as is,\n",
    "#         since the one-hot encoding will be done by our own pipeline. Along with\n",
    "#         the feature dataframe, you'll need to output lists of numberical features\n",
    "#         and categorical features as well.\n",
    "\n",
    "#         Returns\n",
    "#           pd.DataFrame: User feature dataframe\n",
    "#           List[str]: List of numerical features. E.g. ['feat_1', 'feat_3, ...]\n",
    "#           List[str]: List of categorical features. E.g. ['feat_2', 'feat_4, ...]\n",
    "#         \"\"\"\n",
    "\n",
    "#         feature_df = self.generated_content_metadata[['content_id']].drop_duplicates().copy()\n",
    "\n",
    "#         np.random.seed(1234)\n",
    "#         feature_df[['content_feat_0', 'content_feat_1']] = np.random.rand(len(feature_df), 2)\n",
    "\n",
    "#         feature_df['content_feat_2'] = np.random.choice(['a', 'b', 'c'], len(feature_df))\n",
    "\n",
    "\n",
    "#         return feature_df, ['content_feat_0', 'content_feat_1'], ['content_feat_2']\n",
    "\n",
    "#     def get_Ys(self, engagement_data) -> pd.DataFrame:\n",
    "#         \"\"\"Engineers taget variable that you are predicting.\n",
    "#         Args\n",
    "#             engagement_data (pd.DataFrame): Engagement data.\n",
    "#         Returns\n",
    "#             pd.DataFrame: Dataframe of 5 columns;\n",
    "#                 'user_id', 'content_id', 'like', 'dislike', 'engage_time'\n",
    "#         \"\"\"\n",
    "\n",
    "#         np.random.seed(42)\n",
    "\n",
    "#         target_df = engagement_data[['user_id', 'content_id']].drop_duplicates().copy()\n",
    "\n",
    "#         like_dislike = np.random.choice([-1, 0, 1], len(target_df), p=[.5, .3, .2])\n",
    "#         target_df['like'] = (like_dislike > 0).astype(int)\n",
    "#         target_df['dislike'] = (like_dislike < 0).astype(int)\n",
    "\n",
    "#         target_df['engage_time'] = np.random.uniform(0, 1, len(target_df))\n",
    "\n",
    "#         return target_df\n",
    "\n",
    "#     def predict(self, X: pd.DataFrame) -> Tuple[list, list, list]:\n",
    "#         \"\"\"Predicts the 3 target variables by using the model that you trained.\n",
    "#         Make sure you load the model properly.\n",
    "\n",
    "#         Args:\n",
    "#             X (pd.DataFrame): Feature dataframe with 2-level index of (user_id, content_id)\n",
    "\n",
    "#         Returns:\n",
    "#             (list, list, list): (predicted prbability of like,\n",
    "#                                  predicted probability of dislike,\n",
    "#                                  predicted engagement time)\n",
    "#         \"\"\"\n",
    "\n",
    "#         model = self.load_model()\n",
    "\n",
    "#         pred_like = model['like'].predict(X)\n",
    "#         pred_dislike = model['dislike'].predict(X)\n",
    "#         pred_engtime = model['engage_time'].predict(X)\n",
    "\n",
    "#         return pred_like, pred_dislike, pred_engtime\n",
    "\n",
    "#     def rank(self,\n",
    "#              score_df: pd.DataFrame,\n",
    "#              user_id: int,\n",
    "#              content_ids: Optional[list] = None) -> list:\n",
    "\n",
    "#         \"\"\"Ranks the items for a given user based on your own criteria.\n",
    "\n",
    "#         Args:\n",
    "#             score_df (pd.DataFrame): Predicted-score Dataframe of columns;\n",
    "#                 'user_id', 'content_id', 'like', 'dislike', 'engage_time', and\n",
    "#                 also columns for content metadata.\n",
    "#             user_id (int): User ID to rank the items for.\n",
    "#             content_ids (Optional[list]): List of content ids to be considered for ranking.\n",
    "#         \"\"\"\n",
    "\n",
    "#         score_df = score_df[score_df['user_id'] == user_id]\n",
    "#         ranked_pred = score_df.sort_values('like', ascending=False)\n",
    "\n",
    "#         return ranked_pred['content_id'].tolist()\n",
    "\n",
    "#     def load_model(self) -> object:\n",
    "#         \"\"\"Loads your model. Since different ML frameworks requires different\n",
    "#         ways to load the model. Change this to reflect your choice of framework.\n",
    "\n",
    "#         Returns:\n",
    "#             object: Model object\n",
    "#         \"\"\"\n",
    "\n",
    "#         with open(f'{self.objects_dir}/model.pkl', 'rb') as f:\n",
    "#             return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMev-xwJ11d5"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep6q_8-fH0Na"
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOIw6gAeDVSp"
   },
   "outputs": [],
   "source": [
    "engagement_data = pd.read_csv('sample_data/engagement.csv', sep=\"\\t\")\n",
    "content_meta = pd.read_csv('sample_data/generated_content_metadata.csv', sep=\"\\t\")\n",
    "\n",
    "interactions = engagement_data[\n",
    "    ['user_id', 'content_id']].drop_duplicates()\n",
    "\n",
    "interactions_train, interactions_test = train_test_split(interactions, test_size=0.2, random_state=42)\n",
    "\n",
    "engagement_train = pd.merge(interactions_train, engagement_data, how='left', on=['user_id', 'content_id'])\n",
    "engagement_test = pd.merge(interactions_test, engagement_data, how='left', on=['user_id', 'content_id'])\n",
    "\n",
    "engagement_train.to_csv('sample_data/engagement_train.csv', sep=\"\\t\")\n",
    "engagement_test.to_csv('sample_data/engagement_test.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvMO4tMXe9io"
   },
   "outputs": [],
   "source": [
    "#@title get training data\n",
    "data_collector = DataCollectorGolf(\n",
    "    engagement_path='sample_data/engagement_train.csv',\n",
    "    content_meta_path='sample_data/generated_content_metadata.csv'\n",
    "    )\n",
    "\n",
    "X_train = data_collector.gen_model_input(is_train=True)\n",
    "y_train = data_collector.gen_target_vars()\n",
    "\n",
    "# ensure that each row of y_train corresponds to the correct user-content in X_train\n",
    "y_train = y_train.reindex(index=X_train.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_train.head()"
   ],
   "metadata": {
    "id": "pgOobJtSCU2P",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "outputId": "63955df9-ab49-4c02-9db3-06fd27167b9f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    user_numerical_feature  user_time_elapsed  \\\n",
       "user_id content_id                                              \n",
       "45      119192                   -0.473025          -0.670195   \n",
       "13      107134                   -0.477480          -0.646125   \n",
       "65      33184                    -0.242882           1.505086   \n",
       "30      105300                    0.481485          -0.656776   \n",
       "25      44274                     2.388704           1.583192   \n",
       "\n",
       "                    content_numerical_feature_guidance_scale  \\\n",
       "user_id content_id                                             \n",
       "45      119192                                     -1.867545   \n",
       "13      107134                                      2.517037   \n",
       "65      33184                                      -0.040636   \n",
       "30      105300                                     -0.406018   \n",
       "25      44274                                       0.324746   \n",
       "\n",
       "                    content_numerical_feature_num_inference_steps  \\\n",
       "user_id content_id                                                  \n",
       "45      119192                                          -2.395867   \n",
       "13      107134                                           0.420667   \n",
       "65      33184                                            0.420667   \n",
       "30      105300                                           0.420667   \n",
       "25      44274                                            0.420667   \n",
       "\n",
       "                    user_categorical_feature_Like  \\\n",
       "user_id content_id                                  \n",
       "45      119192                                0.0   \n",
       "13      107134                                1.0   \n",
       "65      33184                                 0.0   \n",
       "30      105300                                1.0   \n",
       "25      44274                                 0.0   \n",
       "\n",
       "                    user_categorical_feature_MillisecondsEngagedWith  \\\n",
       "user_id content_id                                                     \n",
       "45      119192                                                   1.0   \n",
       "13      107134                                                   0.0   \n",
       "65      33184                                                    1.0   \n",
       "30      105300                                                   0.0   \n",
       "25      44274                                                    1.0   \n",
       "\n",
       "                    content_source_human_prompts_0  \\\n",
       "user_id content_id                                   \n",
       "45      119192                                 1.0   \n",
       "13      107134                                 0.0   \n",
       "65      33184                                  1.0   \n",
       "30      105300                                 0.0   \n",
       "25      44274                                  1.0   \n",
       "\n",
       "                    content_source_human_prompts_1  content_source_r/pics_0  \\\n",
       "user_id content_id                                                            \n",
       "45      119192                                 0.0                      0.0   \n",
       "13      107134                                 1.0                      1.0   \n",
       "65      33184                                  0.0                      1.0   \n",
       "30      105300                                 1.0                      1.0   \n",
       "25      44274                                  0.0                      1.0   \n",
       "\n",
       "                    content_source_r/pics_1  content_source_r/scifi_0  \\\n",
       "user_id content_id                                                      \n",
       "45      119192                          1.0                       1.0   \n",
       "13      107134                          0.0                       1.0   \n",
       "65      33184                           0.0                       1.0   \n",
       "30      105300                          0.0                       1.0   \n",
       "25      44274                           0.0                       1.0   \n",
       "\n",
       "                    content_source_r/scifi_1  \n",
       "user_id content_id                            \n",
       "45      119192                           0.0  \n",
       "13      107134                           0.0  \n",
       "65      33184                            0.0  \n",
       "30      105300                           0.0  \n",
       "25      44274                            0.0  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-d9465025-bc2e-413b-bba1-7fc92f6d1279\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user_numerical_feature</th>\n",
       "      <th>user_time_elapsed</th>\n",
       "      <th>content_numerical_feature_guidance_scale</th>\n",
       "      <th>content_numerical_feature_num_inference_steps</th>\n",
       "      <th>user_categorical_feature_Like</th>\n",
       "      <th>user_categorical_feature_MillisecondsEngagedWith</th>\n",
       "      <th>content_source_human_prompts_0</th>\n",
       "      <th>content_source_human_prompts_1</th>\n",
       "      <th>content_source_r/pics_0</th>\n",
       "      <th>content_source_r/pics_1</th>\n",
       "      <th>content_source_r/scifi_0</th>\n",
       "      <th>content_source_r/scifi_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <th>119192</th>\n",
       "      <td>-0.473025</td>\n",
       "      <td>-0.670195</td>\n",
       "      <td>-1.867545</td>\n",
       "      <td>-2.395867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>107134</th>\n",
       "      <td>-0.477480</td>\n",
       "      <td>-0.646125</td>\n",
       "      <td>2.517037</td>\n",
       "      <td>0.420667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <th>33184</th>\n",
       "      <td>-0.242882</td>\n",
       "      <td>1.505086</td>\n",
       "      <td>-0.040636</td>\n",
       "      <td>0.420667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>105300</th>\n",
       "      <td>0.481485</td>\n",
       "      <td>-0.656776</td>\n",
       "      <td>-0.406018</td>\n",
       "      <td>0.420667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <th>44274</th>\n",
       "      <td>2.388704</td>\n",
       "      <td>1.583192</td>\n",
       "      <td>0.324746</td>\n",
       "      <td>0.420667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9465025-bc2e-413b-bba1-7fc92f6d1279')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d9465025-bc2e-413b-bba1-7fc92f6d1279 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d9465025-bc2e-413b-bba1-7fc92f6d1279');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-2af6fb2f-96af-4ae4-9666-cc51844ec382\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2af6fb2f-96af-4ae4-9666-cc51844ec382')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-2af6fb2f-96af-4ae4-9666-cc51844ec382 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vw2A1Ha_HwbZ"
   },
   "source": [
    "## Training: Create your own training\n",
    "Make sure you save the model somewhere so you can send the model file to the professor later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32RUcYxekqqT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tCAKgIakqqT"
   },
   "source": [
    "## like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvVkAIs5kqqT",
    "outputId": "b6451ba0-3a92-47fd-b2f9-5ae430d841e4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, random_state=0)"
      ],
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=3, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=3, random_state=0)</pre></div></div></div></div></div>"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "\n",
    "#model = LinearSVC(dual=\"auto\", random_state=1, tol=1e-5)\n",
    "#model1 = LogisticRegression()\n",
    "model1 = RandomForestClassifier(max_depth=3, random_state=0,)\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "model1.fit(X_train, y_train['like'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKQ9FDvZkqqU"
   },
   "outputs": [],
   "source": [
    "a = model1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Gm9MNsEkqqU",
    "outputId": "620ef57c-8028-47b1-c2e0-329a1b53f307",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.713128038897893"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "precision_score(y_train['like'],a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bh4OMxt9kqqU",
    "outputId": "292e31e5-d383-4822-d536-853672d15846",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.030559799972218363"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "recall_score(y_train['like'],a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y07HcSHVkqqU"
   },
   "source": [
    "## dislike model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PCTmbRgkqqU",
    "outputId": "55ddf4ce-91df-481c-a009-08c2c0017f2a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, random_state=0)"
      ],
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=3, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=3, random_state=0)</pre></div></div></div></div></div>"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "model2 = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "model2.fit(X_train, y_train['dislike'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOZLAT2YkqqU"
   },
   "outputs": [],
   "source": [
    "a = model2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsrOve3LkqqU",
    "outputId": "a98b5418-0757-49a2-d3cf-c5d76dc92ca7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7569573283858998"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "precision_score(y_train['dislike'],a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBbOW-AZkqqU",
    "outputId": "883694c7-7ba7-4dbc-90c6-305b7c65a042",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.12503830830524057"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "recall_score(y_train['dislike'],a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Andc889okqqV"
   },
   "source": [
    "## engagement model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyYzV0tbkqqV",
    "outputId": "92630446-e41e-4918-bbde-8e1f16ab4802",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=10, random_state=0)"
      ],
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, random_state=0)</pre></div></div></div></div></div>"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model3 = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "model3.fit(X_train, y_train['engage_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFHI_KgWkqqV"
   },
   "outputs": [],
   "source": [
    "a = model3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnDMO6vdkqqV",
    "outputId": "41fc34fa-d87d-407d-acf2-16a5026e2eb7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7944743583016.646"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "mean_squared_error( y_train['engage_time'],a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yYMsgEGkqqV"
   },
   "source": [
    "## Dump to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cakxVtq9kqqV"
   },
   "outputs": [],
   "source": [
    "model = {\n",
    "    'like': model1,\n",
    "    'dislike': model2,\n",
    "    'engage_time': model3\n",
    "}\n",
    "with open('sample_data/model.pkl','wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHQoFOGdIOm_"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxZ6qbDwGXRp"
   },
   "outputs": [],
   "source": [
    "# Simulates contents filtered from previous stage.\n",
    "# Feel free to change this to reflect your previous stage.\n",
    "\n",
    "sample_contents = content_meta['content_id'].sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwBbNw4I08ah"
   },
   "outputs": [],
   "source": [
    "# Get true target variables\n",
    "y_true = data_collector.gen_target_vars(engagement_test)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = data_collector.score(content_ids = sample_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7WmMuMc5C_K",
    "outputId": "efb2ace7-4a2e-4701-ac6a-e0adb01570c7"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'like': {'precision': 1.0, 'recall': 0.02857142857142857},\n",
       " 'dislike': {'precision': 0.5, 'recall': 0.08333333333333333},\n",
       " 'engage_time': {'rmse': 367852.87682204344}}"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "thres_like = 0.5\n",
    "thres_dislike = 0.5\n",
    "evaluate(y_true, y_pred, thres_like, thres_dislike)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVqi5AsJBBKq"
   },
   "source": [
    "# Inference Example_Archit plz edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Bq4NJDP93om"
   },
   "outputs": [],
   "source": [
    "sample_contents = content_meta['content_id'].sample(frac=0.01)  # simulated contents filtered from previous stage\n",
    "\n",
    "\n",
    "data_collector = DataCollectorGolf(\n",
    "    engagement_path='sample_data/engagement_train.csv',  # will be None in real production\n",
    "    content_meta_path='sample_data/generated_content_metadata.csv'  # will be None in real production\n",
    "    )\n",
    "\n",
    "recs = data_collector.recommend(user_id=8, content_ids=sample_contents, top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cUZs7nqjBfY1",
    "outputId": "a6293a70-dfe6-4f92-bb59-783208f22957"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[94687,\n",
       " 84601,\n",
       " 93096,\n",
       " 94714,\n",
       " 95331,\n",
       " 95368,\n",
       " 95786,\n",
       " 91382,\n",
       " 101927,\n",
       " 102460,\n",
       " 104575,\n",
       " 88854,\n",
       " 87048,\n",
       " 93945,\n",
       " 105932,\n",
       " 94738,\n",
       " 91441,\n",
       " 100348,\n",
       " 88188,\n",
       " 104901]"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "recs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
